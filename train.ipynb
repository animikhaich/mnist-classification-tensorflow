{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Constants\n",
    "BATCH_SIZE = 128\n",
    "GPU = 0\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 10\n",
    "DATASET_NAME = 'mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset from Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.0.1\n",
      "Tensorflow Datasets Version: 3.1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since by default tensorflow uses up all available memory in the GPU,\n",
    "We will set it to allow memory growth.\n",
    "Also, here we check if the enterred data is correct, before proceeding\n",
    "\"\"\" \n",
    "\n",
    "import os\n",
    "\n",
    "# Enable/Disable GPU and Force Allow Memory Growth\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU)\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# If GPU is available, Configure Tensorflow to allow memory growth\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    # For TF 1x\n",
    "    if int(tf.__version__.split('.')[0]) == 1:\n",
    "        from tensorflow.keras.backend import set_session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.Session(config=config)\n",
    "        set_session(session)\n",
    "\n",
    "    # For TF 2x\n",
    "    else:\n",
    "        gpu_devices = tf.config.experimental.list_physical_devices(\n",
    "            'GPU'\n",
    "        )\n",
    "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "\n",
    "\n",
    "# Verify Compaibility of Version of TFDS and Check if Dataset exists\n",
    "assert int(tfds.__version__.split('.')[0]) == 3, \"Please download Tensorflow Datasets v3.x\"\n",
    "assert DATASET_NAME in tfds.list_builders(), \"The Entered Dataset is not found, please download it manually\"\n",
    "\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "print(f\"Tensorflow Datasets Version: {tfds.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info: tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    version=3.0.1,\n",
      "    description='The MNIST database of handwritten digits.',\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    total_num_examples=70000,\n",
      "    splits={\n",
      "        'test': 10000,\n",
      "        'train': 60000,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the dataset and split it into train, validation and test set\n",
    "Since this does not come with a vaildation split, we are creating one\n",
    "In this case, we are doing a 80:20 split for train and validation set\n",
    "And we are keeping the test set untouched\n",
    "Even though the dataset is small, let's follow some rules and load at a given batch_size\n",
    "\"\"\"\n",
    "dataset, info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train[:80%]', 'train[80%:]', 'test'],\n",
    "    shuffle_files=True,\n",
    "    data_dir='data',\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "print(\"Dataset Info:\", info)\n",
    "\n",
    "# Seperate the train and test data\n",
    "train_data, val_data, test_data = dataset\n",
    "train_data, val_data = train_data.repeat(), val_data.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples: 48000\n",
      "Number of Validation Samples: 12000\n",
      "Number of Testing Samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Verify the Number of training, validation and testing samples\n",
    "print(f\"Number of Training Samples: {info.splits['train[:80%]'].num_examples}\")\n",
    "print(f\"Number of Validation Samples: {info.splits['train[80%:]'].num_examples}\")\n",
    "print(f\"Number of Testing Samples: {info.splits['test'].num_examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow has a very bad implementation of the datasets module.\n",
    "# Hence, we will be creating a class for Image Augmentation.\n",
    "# -- More Augmnetaion TO BE ADDED -- #\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255., tf.one_hot(indices=label, depth=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of X: (128, 28, 28, 1)\n",
      "Batch of y: (128, 10)\n"
     ]
    }
   ],
   "source": [
    "# Verify that we are getting the correct image shape from the generator\n",
    "generated_batch = tfds.as_numpy(train_data.map(normalize_img)).__next__()\n",
    "print(\"Batch of X:\", generated_batch[0].shape)\n",
    "print(\"Batch of y:\", generated_batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 19s 25ms/step - loss: 0.1863 - categorical_accuracy: 0.9439 - precision: 0.9636 - recall: 0.9294 - false_negatives: 6781.0000 - false_positives: 3374.0000 - val_loss: 0.0475 - val_categorical_accuracy: 0.9862 - val_precision: 0.9882 - val_recall: 0.9843 - val_false_negatives: 376.0000 - val_false_positives: 280.0000\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 0.0653 - categorical_accuracy: 0.9802 - precision: 0.9833 - recall: 0.9779 - false_negatives: 2123.0000 - false_positives: 1598.0000 - val_loss: 0.0402 - val_categorical_accuracy: 0.9879 - val_precision: 0.9887 - val_recall: 0.9874 - val_false_negatives: 302.0000 - val_false_positives: 270.0000\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 0.0458 - categorical_accuracy: 0.9856 - precision: 0.9873 - recall: 0.9838 - false_negatives: 1551.0000 - false_positives: 1215.0000 - val_loss: 0.0360 - val_categorical_accuracy: 0.9900 - val_precision: 0.9906 - val_recall: 0.9893 - val_false_negatives: 256.0000 - val_false_positives: 224.0000\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 0.0371 - categorical_accuracy: 0.9880 - precision: 0.9893 - recall: 0.9869 - false_negatives: 1262.0000 - false_positives: 1029.0000 - val_loss: 0.0383 - val_categorical_accuracy: 0.9897 - val_precision: 0.9904 - val_recall: 0.9891 - val_false_negatives: 260.0000 - val_false_positives: 230.0000\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 0.0294 - categorical_accuracy: 0.9903 - precision: 0.9913 - recall: 0.9894 - false_negatives: 1014.0000 - false_positives: 838.0000 - val_loss: 0.0326 - val_categorical_accuracy: 0.9905 - val_precision: 0.9911 - val_recall: 0.9900 - val_false_negatives: 238.0000 - val_false_positives: 212.0000\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 0.0260 - categorical_accuracy: 0.9914 - precision: 0.9921 - recall: 0.9908 - false_negatives: 887.0000 - false_positives: 759.0000 - val_loss: 0.0384 - val_categorical_accuracy: 0.9910 - val_precision: 0.9913 - val_recall: 0.9909 - val_false_negatives: 218.0000 - val_false_positives: 208.0000\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.0216 - categorical_accuracy: 0.9929 - precision: 0.9936 - recall: 0.9924 - false_negatives: 734.0000 - false_positives: 617.0000 - val_loss: 0.0334 - val_categorical_accuracy: 0.9915 - val_precision: 0.9915 - val_recall: 0.9912 - val_false_negatives: 210.0000 - val_false_positives: 202.0000\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.0202 - categorical_accuracy: 0.9934 - precision: 0.9938 - recall: 0.9929 - false_negatives: 683.0000 - false_positives: 590.0000 - val_loss: 0.0370 - val_categorical_accuracy: 0.9915 - val_precision: 0.9917 - val_recall: 0.9914 - val_false_negatives: 206.0000 - val_false_positives: 198.0000\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 16s 22ms/step - loss: 0.0183 - categorical_accuracy: 0.9942 - precision: 0.9946 - recall: 0.9937 - false_negatives: 609.0000 - false_positives: 520.0000 - val_loss: 0.0357 - val_categorical_accuracy: 0.9922 - val_precision: 0.9925 - val_recall: 0.9921 - val_false_negatives: 190.0000 - val_false_positives: 178.0000\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.0152 - categorical_accuracy: 0.9950 - precision: 0.9953 - recall: 0.9948 - false_negatives: 504.0000 - false_positives: 454.0000 - val_loss: 0.0376 - val_categorical_accuracy: 0.9918 - val_precision: 0.9919 - val_recall: 0.9917 - val_false_negatives: 198.0000 - val_false_positives: 194.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb504883d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the the model with various metrics\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\n",
    "        tf.metrics.CategoricalAccuracy(), # Alternatively, 'accuracy' can also be used\n",
    "        tf.metrics.Precision(),\n",
    "        tf.metrics.Recall(),\n",
    "        tf.metrics.FalseNegatives(),\n",
    "        tf.metrics.FalsePositives()\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Since the data is being loaded from a generator, we use that to train the model\n",
    "model.fit_generator(\n",
    "    train_data.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE),\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=750,\n",
    "    validation_data=val_data.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE),\n",
    "    validation_steps=187\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0314 - categorical_accuracy: 0.9925 - precision: 0.9925 - recall: 0.9921 - false_negatives: 79.0000 - false_positives: 75.0000\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data.map(normalize_img), use_multiprocessing=True, workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2x]",
   "language": "python",
   "name": "conda-env-tf2x-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
